{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mido import MidiFile, tick2second\n",
    "from pretty_midi import PrettyMIDI\n",
    "import pickle\n",
    "import joblib\n",
    "import subprocess\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "from ExtractBootlegFeatures1 import *\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Bootleg Features from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_Pdf_wrapper(i):\n",
    "    basedir = 'experiments/allBootlegScores-new/'\n",
    "    outdir = '{}/scores/'.format(basedir)\n",
    "    imagedir = '/data1/dyang/Datasets/5000dataset/images1/'\n",
    "    numPdfs=5024;\n",
    "    if i >= numPdfs:\n",
    "        return\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "    outfile = outdir + 'p{}.pkl'.format(str(i))\n",
    "    if i <= 200:\n",
    "        filepath = imagedir + 'p'+str(i)+'/'\n",
    "    else:\n",
    "        filepath = imagedir + 'p'+str(i)+'/'\n",
    "    if os.path.exists(outfile):\n",
    "        print(str(i)+\" is already there\")\n",
    "        return\n",
    "    total_bscore = np.zeros((62,1))\n",
    "    lst = 1 #len(os.listdir(filepath))\n",
    "    if lst == 1:\n",
    "        if i<=200:\n",
    "            imagepath = '20210726165646.jpg' #'p{}.jpg'.format(i)\n",
    "        else:\n",
    "            imagepath = filepath+'p{}.jpg'.format(i)\n",
    "        try:\n",
    "            bscore_query = processImageFile(imagepath,None)\n",
    "        except:\n",
    "            bscore_query = np.zeros((62,1))\n",
    "        total_bscore = np.concatenate((total_bscore, bscore_query),axis=1)\n",
    "    else:\n",
    "        for count in range(lst):\n",
    "            try:\n",
    "                if i<=200:\n",
    "                    imagepath = filepath+'p{}-{}.jpg'.format(i,count)\n",
    "                else:\n",
    "                    imagepath = filepath+'p{}-{}.jpg'.format(i,count)\n",
    "                bscore_query=processImageFile(imagepath,None)\n",
    "            except:\n",
    "                bscore_query = np.zeros((62,1))\n",
    "            total_bscore = np.concatenate((total_bscore, bscore_query),axis=1)\n",
    "    with open(outfile, 'wb') as f:\n",
    "        print(\"Saving p\" + str(i))\n",
    "        pickle.dump(total_bscore, f)\n",
    "    print(total_bscore.shape)\n",
    "        #visualizeLongBootlegScore(total_bscore, [13,15,17,19,21,35,37,39,41,43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 is already there\n"
     ]
    }
   ],
   "source": [
    "convert_Pdf_wrapper(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = [[i] for i in range(1,4825)]\n",
    "n_cores = 28\n",
    "\n",
    "pool = multiprocessing.Pool(processes=n_cores)\n",
    "outputs = list(pool.starmap(convert_Pdf_wrapper, inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Reverse Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_to_num = {}\n",
    "piecedir = \"cfg_files/db.list\"\n",
    "with open(piecedir, \"r\")as f:\n",
    "    for i, piece in enumerate(f):\n",
    "        piece = piece.strip().strip('\\n')\n",
    "        piece =piece.split('/')[-1][:-4]\n",
    "        piece_to_num[i] = piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"piece_to_num.pkl\",'wb')as f:\n",
    "    pickle.dump(piece_to_num,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bootlegHash(arr):\n",
    "    bitstring = \"\"\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i]==1:\n",
    "            bitstring+=\"1\"\n",
    "        else:\n",
    "            bitstring +=\"0\"\n",
    "    bitstring = bitstring+\"00\"\n",
    "    hashint = int(bitstring, 2)\n",
    "    hashint = np.uint64(hashint)\n",
    "    return hashint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getTotalBscore(bscore_file):\n",
    "    bscore_array = []\n",
    "    with open (bscore_file,'rb') as f:\n",
    "        bscore_array = pickle.load(f)\n",
    "    f.close()\n",
    "    total_bscore = np.array([]).reshape(62,0)\n",
    "    page_array = []\n",
    "    for page in bscore_array:\n",
    "        total_page = np.array([]).reshape(62,0)\n",
    "        for num in page:\n",
    "            col = np.array(decodeColumn(num)).reshape(62,-1)\n",
    "            total_page = np.concatenate((total_page,col),axis=1)\n",
    "        total_bscore = np.concatenate((total_bscore,total_page),axis=1)\n",
    "        page_array.append(total_page)\n",
    "    return total_bscore,page_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeColumn(num):\n",
    "    col = []\n",
    "    for i in range(62):\n",
    "        col.insert(0,num%2)\n",
    "        num = int(num/2)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getRandomdb(size, mode, seed = 1):\n",
    "    # Generates db.list\n",
    "    f = open(\"cfg_files/db.list\", \"w\")\n",
    "    random.seed(seed)\n",
    "    randomDir = []\n",
    "    if(mode == \"all\"):\n",
    "        directory = 'experiments/bootleg_output/'\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                fname = os.path.join(root,file)\n",
    "                if fname[-4:] == \".pkl\":\n",
    "                    num = fname.split('/')[-1]\n",
    "                    str2 = 'experiments/bootleg_output/'+num+\"\\n\"\n",
    "                    f.write(str2)\n",
    "        f.close()    \n",
    "        return\n",
    "    if size > 200:\n",
    "        randomDir = random.sample(range(201, 36834), size-200)\n",
    "    print(randomDir)\n",
    "    for i in range(1,201):\n",
    "        num = str(i)\n",
    "        str2 = 'experiments/bootleg_output/'+\"p\"+num+\".pkl\"+\"\\n\"\n",
    "        f.write(str2)\n",
    "        \n",
    "    for i in randomDir:\n",
    "        num = str(i)\n",
    "        str2 = 'experiments/bootleg_output/'+\"p\"+num+\".pkl\"+\"\\n\"\n",
    "        f.write(str2)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getRandomdb(200,\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Singular_DB(data, rindex):\n",
    "    for colindex in range(len(data.T)):\n",
    "        col = data.T[colindex]\n",
    "        hashint = bootlegHash(col)\n",
    "        if hashint == 0:\n",
    "            continue\n",
    "        pieceStr = curfile.split('/')[-1][:-4]\n",
    "\n",
    "        if hashint in rindex:\n",
    "            if pieceStr in rindex[hashint]:\n",
    "                rindex[hashint][pieceStr].append(colindex)\n",
    "            else:\n",
    "                rindex[hashint][pieceStr]=[colindex]\n",
    "        else:\n",
    "            rindex[hashint]={}\n",
    "            rindex[hashint][pieceStr]=[colindex]\n",
    "    return rindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_Gram_DB(data, rindex, N_Gram = 3):\n",
    "    for colindex in range(len(data.T)):\n",
    "        cols = []\n",
    "        try:\n",
    "            for i in range(N_Gram):\n",
    "                cols.append(data.T[colindex+i])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        fp = []\n",
    "        equals_Zero = True\n",
    "        for column in cols:\n",
    "            hashint = bootlegHash(column)\n",
    "            fp.append(hashint)\n",
    "            if hashint != 0:\n",
    "                equals_Zero = False\n",
    "        if equals_Zero == True:\n",
    "            continue\n",
    "        fp = tuple(fp)\n",
    "        pieceStr = curfile.split('/')[-1][:-4]\n",
    "        if fp in rindex:\n",
    "            if pieceStr in rindex[fp]:\n",
    "                rindex[fp][pieceStr].append(colindex)\n",
    "            else:\n",
    "                rindex[fp][pieceStr]=[colindex]\n",
    "        else:\n",
    "            rindex[fp]={}\n",
    "            rindex[fp][pieceStr]=[colindex]\n",
    "    return rindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dynamic_N_Gram_DB(data, rindex, rindex_original, threshold_function):\n",
    "    for colindex in range(len(data.T)):\n",
    "        first_col = data.T[colindex]\n",
    "        first_fp = bootlegHash(first_col)\n",
    "        hits = len(rindex_original[fp].keys())\n",
    "        N_Gram = int(threshold_function(hits))\n",
    "        cols = []\n",
    "        try:\n",
    "            for i in range(N_Gram):\n",
    "                cols.append(data.T[colindex+i])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        fp = []\n",
    "        equals_Zero = True\n",
    "        for col in cols:\n",
    "            hashint = bootlegHash(col)\n",
    "            fp.append(hashint)\n",
    "            if hashint != 0:\n",
    "                equals_Zero = False\n",
    "        if equals_Zero == True:\n",
    "            continue\n",
    "        fp = tuple(fp)\n",
    "        pieceStr = curfile.split('/')[-1][:-4]\n",
    "        if fp in rindex:\n",
    "            if pieceStr in rindex[fp]:\n",
    "                rindex[fp][pieceStr].append(colindex)\n",
    "            else:\n",
    "                rindex[fp][pieceStr]=[colindex]\n",
    "        else:\n",
    "            rindex[fp]={}\n",
    "            rindex[fp][pieceStr]=[colindex]\n",
    "    return rindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCountFile(outfile, rindex):\n",
    "    rindex_count = {}\n",
    "    for key in rindex:\n",
    "        count = 0\n",
    "        subDict = rindex[key]\n",
    "        for key1 in subDict:\n",
    "            count += len(subDict[key1])\n",
    "        rindex_count[key] = count\n",
    "    with open (outfile,\"wb\") as f:\n",
    "        pickle.dump(rindex_count,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bootleg_total\\\\dBach,_Johann_Christoph_FriedrichKeyboard_Sonata_in_F_major,_HW_XI', 'bootleg_total\\\\dBrassin,_LouisTranscription_-_Bach', 'bootleg_total\\\\dChopin,_Fr%C3%A9d%C3%A9ricHexam%C3%A9ron', 'bootleg_total\\\\dCzerny,_CarlIreland', 'bootleg_total\\\\dGouin,_PierreSuite_in_A_major,_TWV_32', 'bootleg_total\\\\dGrey,_A._OgilvieScottish_Music', 'bootleg_total\\\\dH%C3%B6ger,_AntonDivertimento_in_C_major,_Hob.XVI', 'bootleg_total\\\\dH%C3%B6ger,_AntonKeyboard_Sonata_in_D_major,_Hob.XVI', 'bootleg_total\\\\dH%C3%B6ger,_AntonKeyboard_Sonata_in_G_major,_Hob.XVI', 'bootleg_total\\\\dH%C3%B6ger,_AntonPartita_in_E_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephCapriccio_in_G_major,_Hob.XVII', 'bootleg_total\\\\dHaydn,_JosephDivertimento_in_A-flat_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephDivertimento_in_A_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephDivertimento_in_C_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephDivertimento_in_D_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephDivertimento_in_E-flat_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephDivertimento_in_F_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephDivertimento_in_G_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephFantasia_in_C_major,_Hob.XVII', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_A-flat_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_A_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_B-flat_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_B_minor,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_C-sharp_minor,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_C_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_C_minor,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_D_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_E-flat_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_E_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_E_minor,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_F_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_G_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephKeyboard_Sonata_in_G_minor,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephPartita_in_B-flat_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephPartita_in_D_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephPartita_in_E_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephPartita_in_G_major,_Hob.XVI', 'bootleg_total\\\\dHaydn,_JosephVariations_in_C_major,_Hob.XVII', 'bootleg_total\\\\dHaydn,_JosephVariations_in_E-flat_major,_Hob.XVII', 'bootleg_total\\\\dHaydn,_JosephVariations_in_F_minor,_Hob.XVII', 'bootleg_total\\\\dHenriques,_RobertM%C3%A9ditation', 'bootleg_total\\\\dHeusler,_MagnusHarmonia_bis_dena,_amoena', 'bootleg_total\\\\dSmetana,_Bed%C5%99ich5_Waltzes,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichAllegro_capriccioso,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichAndante_in_E-flat_major,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichA_Treasure_of_Melodies,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichBagatelles_et_impromptus,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichBettina_Polka,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichCzech_Dances_II,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichErinnerung_an_Pilsen,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichGeorgina_Polka,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichLouisina_Polka,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichMacbeth_and_the_Witches,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichMarch_of_the_Prague_Student_Legion,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichNational_Guard_March,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichOn_the_Seashore,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichPiano_Sonata_in_G_minor,_JB_3', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichPolka_in_A_major,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichPolka_in_E-flat_major,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichPolka_in_E_major,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichPolka_in_F_minor,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichPolka_in_G_minor,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichR%C3%AAves,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichTo_Our_Girls,_JB_1', 'bootleg_total\\\\dSmetana,_Bed%C5%99ichWedding_Scenes,_JB_1', 'bootleg_total\\\\dTelemann,_Georg_Philipp6_Overtures_for_Clavier,_TWV_32', 'bootleg_total\\\\dTelemann,_Georg_PhilippFugierende_und_ver%C3%A4ndernde_Chor%C3%A4le,_TWV_31', 'bootleg_total\\\\dTelemann,_Georg_PhilippFugues_l%C3%A9g%C3%A8res_%26_petits_jeux,_TWV_30', 'bootleg_total\\\\dTelemann,_Georg_PhilippSuite_in_A_major,_TWV_32', 'bootleg_total\\\\dWolff,_%C3%89douardHomage_%C3%A0_Chopin', 'bootleg_total\\\\dZwart,_JanFantasie_en_Fuga,_Psalm_72', '']\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "rindex = {}\n",
    "fpMap = {}\n",
    "filelist = 'cfg_files\\\\db.list'\n",
    "N=1\n",
    "outfile = 'G:\\\\experiments\\\\indices\\\\N_Gram_{}_ALL.pkl'.format(N)\n",
    "mode = \"N_GRAM\"\n",
    "threshold_function = lambda x: 3*x/10000 + 1\n",
    "with open(filelist, 'r') as f:\n",
    "    failed = []\n",
    "    for curfile in f:\n",
    "        curfile = curfile.strip().strip('\\n')\n",
    "        #print(\"Processed:\", count)\n",
    "        try:\n",
    "            num = curfile.split('\\\\')[-1][0]\n",
    "            if(num == 'd'):\n",
    "                data, _ = getTotalBscore(curfile)\n",
    "            else:\n",
    "                with open(curfile, 'rb') as pickle_file:\n",
    "                    data = pickle.load(pickle_file)\n",
    "            if mode == \"SINGULAR\":\n",
    "                rindex = Singular_DB(data, rindex)\n",
    "            elif mode == \"N_GRAM\":\n",
    "                rindex = N_Gram_DB(data, rindex, N_Gram=N)\n",
    "            elif mode == \"DYNAMIC_N_GRAM\":\n",
    "                rindex = Dynamic_N_Gram_DB(data, rindex, rindex_original, threshold_function)\n",
    "        except:\n",
    "            failed.append(curfile)\n",
    "    print(failed)\n",
    "with open(outfile,'wb') as f:\n",
    "    pickle.dump(rindex,f)\n",
    "if mode == \"N_GRAM\":\n",
    "    outfile = os.path.splitext(outfile)[0][:-3]+\"COUNT.pkl\"\n",
    "    createCountFile(outfile, rindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createCountFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1088/3169368984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'experiments/indices/Dynamic_N_GRAM_COUNT.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcreateCountFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'createCountFile' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"experiments/indices/Dynamic_N_GRAM_ALL(2).pkl\",'rb')as f:\n",
    "    rindex = pickle.load(f)\n",
    "outfile = 'experiments/indices/Dynamic_N_GRAM_COUNT.pkl'\n",
    "createCountFile(outfile,rindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCountFile(outfile,rindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造db.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"bootleg_total/\"\n",
    "filelist = 'cfg_files/db.list'\n",
    "with open(filelist,\"w\") as f:\n",
    "    for root,dirs,files in os.walk(basepath):\n",
    "        for filename in files:\n",
    "            f.write(os.path.join(root,filename)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = 'cfg_files/pb.list'\n",
    "with open(filelist,'w') as f:\n",
    "    for i in range(1,201):\n",
    "        f.write('bootleg_total/p'+str(i)+'.pkl\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标题\n",
    "## 2级标题\n",
    "1. alsjd\n",
    "2. alodj\n",
    "3. aasdfbv\n",
    "\n",
    "|one|two|three|\n",
    "|-|-|-|\n",
    "|1323|2|3|\n",
    "|32|421|33|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|one|two|three|\n",
    "|:-:|:-:|:-:|\n",
    "|1323|2|3|\n",
    "|32|421|33|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">asldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
